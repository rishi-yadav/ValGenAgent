{
  "test_plan": "cutlass_flash_attention_decode",
  "tests": {
    "test_category": "cutlass_flash_attention_decode",
    "implementation_file": "xe_flash_decode.cpp",
    "test_cases": [
      {
        "test_id": "REQ_001",
        "description": "Write 5 new tests cases for flash attention decode that is for different LLM configurations eg: gpt,llama etc. Override existing TestFlashDecodeAll function if required for better quality tests."
      }
    ]
  }
}